{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd994898-1a68-4c71-873a-ac105a5a37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187fad91-7f2c-4052-877c-67d926558543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# known parameters\n",
    "weight=0.7\n",
    "bias=0.3\n",
    "\n",
    "# Create data\n",
    "start = 0\n",
    "end=1\n",
    "step=0.02\n",
    "X=torch.arange(start,end,step).unsqueeze(dim=1)\n",
    "y=weight * X + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498362b9-88bb-4f5d-8b58-5a6fd452e4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0200],\n",
       "        [0.0400],\n",
       "        [0.0600],\n",
       "        [0.0800],\n",
       "        [0.1000],\n",
       "        [0.1200],\n",
       "        [0.1400],\n",
       "        [0.1600],\n",
       "        [0.1800],\n",
       "        [0.2000],\n",
       "        [0.2200],\n",
       "        [0.2400],\n",
       "        [0.2600],\n",
       "        [0.2800],\n",
       "        [0.3000],\n",
       "        [0.3200],\n",
       "        [0.3400],\n",
       "        [0.3600],\n",
       "        [0.3800],\n",
       "        [0.4000],\n",
       "        [0.4200],\n",
       "        [0.4400],\n",
       "        [0.4600],\n",
       "        [0.4800],\n",
       "        [0.5000],\n",
       "        [0.5200],\n",
       "        [0.5400],\n",
       "        [0.5600],\n",
       "        [0.5800],\n",
       "        [0.6000],\n",
       "        [0.6200],\n",
       "        [0.6400],\n",
       "        [0.6600],\n",
       "        [0.6800],\n",
       "        [0.7000],\n",
       "        [0.7200],\n",
       "        [0.7400],\n",
       "        [0.7600],\n",
       "        [0.7800],\n",
       "        [0.8000],\n",
       "        [0.8200],\n",
       "        [0.8400],\n",
       "        [0.8600],\n",
       "        [0.8800],\n",
       "        [0.9000],\n",
       "        [0.9200],\n",
       "        [0.9400],\n",
       "        [0.9600],\n",
       "        [0.9800]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7520fd5-1997-4971-8407-ee37b4b76413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd31938-9122-414a-ae7d-9f950c3b4be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000],\n",
       "        [0.3140],\n",
       "        [0.3280],\n",
       "        [0.3420],\n",
       "        [0.3560],\n",
       "        [0.3700],\n",
       "        [0.3840],\n",
       "        [0.3980],\n",
       "        [0.4120],\n",
       "        [0.4260],\n",
       "        [0.4400],\n",
       "        [0.4540],\n",
       "        [0.4680],\n",
       "        [0.4820],\n",
       "        [0.4960],\n",
       "        [0.5100],\n",
       "        [0.5240],\n",
       "        [0.5380],\n",
       "        [0.5520],\n",
       "        [0.5660],\n",
       "        [0.5800],\n",
       "        [0.5940],\n",
       "        [0.6080],\n",
       "        [0.6220],\n",
       "        [0.6360],\n",
       "        [0.6500],\n",
       "        [0.6640],\n",
       "        [0.6780],\n",
       "        [0.6920],\n",
       "        [0.7060],\n",
       "        [0.7200],\n",
       "        [0.7340],\n",
       "        [0.7480],\n",
       "        [0.7620],\n",
       "        [0.7760],\n",
       "        [0.7900],\n",
       "        [0.8040],\n",
       "        [0.8180],\n",
       "        [0.8320],\n",
       "        [0.8460],\n",
       "        [0.8600],\n",
       "        [0.8740],\n",
       "        [0.8880],\n",
       "        [0.9020],\n",
       "        [0.9160],\n",
       "        [0.9300],\n",
       "        [0.9440],\n",
       "        [0.9580],\n",
       "        [0.9720],\n",
       "        [0.9860]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be653009-f183-4608-acfb-f66ff4bb3682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15610cac-8d8a-40b2-a4ab-1f3fd4109590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b7251d-b585-4d05-9dfd-0960b061de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        self.bias=nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # x is input\n",
    "            return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c82b13-1401-45a9-92a8-e2fc473eab63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_lr=LinearRegressionModel()\n",
    "\n",
    "list(model_lr.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc269bfc-6b46-4b50-8021-76b5b11d1cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List named parameters \n",
    "model_lr.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b7fbbf-e747-44bd-a79e-dcc06c34d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with model\n",
    "with torch.inference_mode(): \n",
    "    y_preds = model_lr(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a880854-ba5f-48ad-b956-37e70c5973e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3645],\n",
       "        [0.3241],\n",
       "        [0.4520],\n",
       "        [0.1490],\n",
       "        [0.2096],\n",
       "        [0.1625],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.3106],\n",
       "        [0.4318]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a412820-f5ef-4a5a-aa01-d93ad28c9af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7900],\n",
       "        [0.7060],\n",
       "        [0.9720],\n",
       "        [0.3420],\n",
       "        [0.4680],\n",
       "        [0.3700],\n",
       "        [0.8740],\n",
       "        [0.8880],\n",
       "        [0.6780],\n",
       "        [0.9300]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d71f638e-192f-49f0-b039-e55f5f91d906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples: 10\n",
      "Number of predictions made: 10\n",
      "Predicted values:\n",
      "tensor([[0.3645],\n",
      "        [0.3241],\n",
      "        [0.4520],\n",
      "        [0.1490],\n",
      "        [0.2096],\n",
      "        [0.1625],\n",
      "        [0.4049],\n",
      "        [0.4116],\n",
      "        [0.3106],\n",
      "        [0.4318]])\n"
     ]
    }
   ],
   "source": [
    "# Check the predictions\n",
    "print(f\"Number of testing samples: {len(X_test)}\") \n",
    "print(f\"Number of predictions made: {len(y_preds)}\")\n",
    "print(f\"Predicted values:\\n{y_preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cee668b1-3343-4af2-9cd4-db34db783fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4255],\n",
       "        [0.3819],\n",
       "        [0.5200],\n",
       "        [0.1930],\n",
       "        [0.2584],\n",
       "        [0.2075],\n",
       "        [0.4691],\n",
       "        [0.4764],\n",
       "        [0.3674],\n",
       "        [0.4982]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test - y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9adf7321-817b-4c9d-a461-6f26acb6b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e62040-ae14-4af4-a902-cffa3ccaeff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a370b8a-4325-45dd-b673-bececdbeb7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_lr.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4452a7e7-60ba-4208-8b25-00b89a7ae2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a loss function\n",
    "loss_fn=nn.L1Loss()\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer=torch.optim.SGD(params=model_lr.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b326270-3720-40de-9fe2-b206cc59da20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 0.3415827751159668 | MAE Test Loss: 0.3670382499694824 \n",
      "Epoch: 1 | MAE Train Loss: 0.3293831944465637 | MAE Test Loss: 0.35434621572494507 \n",
      "Epoch: 2 | MAE Train Loss: 0.31718358397483826 | MAE Test Loss: 0.34165412187576294 \n",
      "Epoch: 3 | MAE Train Loss: 0.3049840033054352 | MAE Test Loss: 0.3289620876312256 \n",
      "Epoch: 4 | MAE Train Loss: 0.2927843928337097 | MAE Test Loss: 0.31627005338668823 \n",
      "Epoch: 5 | MAE Train Loss: 0.28058475255966187 | MAE Test Loss: 0.3035779595375061 \n",
      "Epoch: 6 | MAE Train Loss: 0.268385112285614 | MAE Test Loss: 0.29088589549064636 \n",
      "Epoch: 7 | MAE Train Loss: 0.2561855614185333 | MAE Test Loss: 0.2781938314437866 \n",
      "Epoch: 8 | MAE Train Loss: 0.24398592114448547 | MAE Test Loss: 0.2655017673969269 \n",
      "Epoch: 9 | MAE Train Loss: 0.23178629577159882 | MAE Test Loss: 0.25280970335006714 \n",
      "Epoch: 10 | MAE Train Loss: 0.21958670020103455 | MAE Test Loss: 0.2401176393032074 \n",
      "Epoch: 11 | MAE Train Loss: 0.20738711953163147 | MAE Test Loss: 0.22742557525634766 \n",
      "Epoch: 12 | MAE Train Loss: 0.19518747925758362 | MAE Test Loss: 0.2147335559129715 \n",
      "Epoch: 13 | MAE Train Loss: 0.18298783898353577 | MAE Test Loss: 0.20204150676727295 \n",
      "Epoch: 14 | MAE Train Loss: 0.1707882583141327 | MAE Test Loss: 0.1893494576215744 \n",
      "Epoch: 15 | MAE Train Loss: 0.15858867764472961 | MAE Test Loss: 0.17665739357471466 \n",
      "Epoch: 16 | MAE Train Loss: 0.14638909697532654 | MAE Test Loss: 0.16396531462669373 \n",
      "Epoch: 17 | MAE Train Loss: 0.13418948650360107 | MAE Test Loss: 0.15127331018447876 \n",
      "Epoch: 18 | MAE Train Loss: 0.12259193509817123 | MAE Test Loss: 0.13985833525657654 \n",
      "Epoch: 19 | MAE Train Loss: 0.11264373362064362 | MAE Test Loss: 0.1304394006729126 \n",
      "Epoch: 20 | MAE Train Loss: 0.10348443686962128 | MAE Test Loss: 0.12300628423690796 \n",
      "Epoch: 21 | MAE Train Loss: 0.09507590532302856 | MAE Test Loss: 0.11603479087352753 \n",
      "Epoch: 22 | MAE Train Loss: 0.08764694631099701 | MAE Test Loss: 0.10974454879760742 \n",
      "Epoch: 23 | MAE Train Loss: 0.08158896863460541 | MAE Test Loss: 0.1038031131029129 \n",
      "Epoch: 24 | MAE Train Loss: 0.0763217955827713 | MAE Test Loss: 0.09830158948898315 \n",
      "Epoch: 25 | MAE Train Loss: 0.07178482413291931 | MAE Test Loss: 0.09427125751972198 \n",
      "Epoch: 26 | MAE Train Loss: 0.06767304986715317 | MAE Test Loss: 0.09050513058900833 \n",
      "Epoch: 27 | MAE Train Loss: 0.06417886167764664 | MAE Test Loss: 0.08700816333293915 \n",
      "Epoch: 28 | MAE Train Loss: 0.061237432062625885 | MAE Test Loss: 0.08378530293703079 \n",
      "Epoch: 29 | MAE Train Loss: 0.05878248065710068 | MAE Test Loss: 0.08084147423505783 \n",
      "Epoch: 30 | MAE Train Loss: 0.056746285408735275 | MAE Test Loss: 0.07818164676427841 \n",
      "Epoch: 31 | MAE Train Loss: 0.05505942180752754 | MAE Test Loss: 0.07581071555614471 \n",
      "Epoch: 32 | MAE Train Loss: 0.053650788962841034 | MAE Test Loss: 0.07373365759849548 \n",
      "Epoch: 33 | MAE Train Loss: 0.05253176763653755 | MAE Test Loss: 0.07165659964084625 \n",
      "Epoch: 34 | MAE Train Loss: 0.051463235169649124 | MAE Test Loss: 0.06987832486629486 \n",
      "Epoch: 35 | MAE Train Loss: 0.0505848228931427 | MAE Test Loss: 0.06810007989406586 \n",
      "Epoch: 36 | MAE Train Loss: 0.04975832253694534 | MAE Test Loss: 0.06662556529045105 \n",
      "Epoch: 37 | MAE Train Loss: 0.04906768724322319 | MAE Test Loss: 0.06515105813741684 \n",
      "Epoch: 38 | MAE Train Loss: 0.04838230460882187 | MAE Test Loss: 0.06398521363735199 \n",
      "Epoch: 39 | MAE Train Loss: 0.04782535508275032 | MAE Test Loss: 0.06281937658786774 \n",
      "Epoch: 40 | MAE Train Loss: 0.047268398106098175 | MAE Test Loss: 0.06165354326367378 \n",
      "Epoch: 41 | MAE Train Loss: 0.04671143740415573 | MAE Test Loss: 0.06048772484064102 \n",
      "Epoch: 42 | MAE Train Loss: 0.04617183655500412 | MAE Test Loss: 0.05963550880551338 \n",
      "Epoch: 43 | MAE Train Loss: 0.04569316655397415 | MAE Test Loss: 0.05878330394625664 \n",
      "Epoch: 44 | MAE Train Loss: 0.04521448165178299 | MAE Test Loss: 0.057931095361709595 \n",
      "Epoch: 45 | MAE Train Loss: 0.04473579302430153 | MAE Test Loss: 0.05707889050245285 \n",
      "Epoch: 46 | MAE Train Loss: 0.044257111847400665 | MAE Test Loss: 0.05622667074203491 \n",
      "Epoch: 47 | MAE Train Loss: 0.0437784269452095 | MAE Test Loss: 0.055374473333358765 \n",
      "Epoch: 48 | MAE Train Loss: 0.04329974204301834 | MAE Test Loss: 0.05452226474881172 \n",
      "Epoch: 49 | MAE Train Loss: 0.04282568767666817 | MAE Test Loss: 0.05398859828710556 \n",
      "Epoch: 50 | MAE Train Loss: 0.04236849024891853 | MAE Test Loss: 0.05313638597726822 \n",
      "Epoch: 51 | MAE Train Loss: 0.04191591590642929 | MAE Test Loss: 0.05260271951556206 \n",
      "Epoch: 52 | MAE Train Loss: 0.04145870357751846 | MAE Test Loss: 0.0520690456032753 \n",
      "Epoch: 53 | MAE Train Loss: 0.041001494973897934 | MAE Test Loss: 0.051535386592149734 \n",
      "Epoch: 54 | MAE Train Loss: 0.0405442900955677 | MAE Test Loss: 0.051001716405153275 \n",
      "Epoch: 55 | MAE Train Loss: 0.040087081491947174 | MAE Test Loss: 0.05046804994344711 \n",
      "Epoch: 56 | MAE Train Loss: 0.039629869163036346 | MAE Test Loss: 0.049934376031160355 \n",
      "Epoch: 57 | MAE Train Loss: 0.03917437791824341 | MAE Test Loss: 0.04908217489719391 \n",
      "Epoch: 58 | MAE Train Loss: 0.03872009366750717 | MAE Test Loss: 0.04854850098490715 \n",
      "Epoch: 59 | MAE Train Loss: 0.03826288506388664 | MAE Test Loss: 0.04801483079791069 \n",
      "Epoch: 60 | MAE Train Loss: 0.03780567646026611 | MAE Test Loss: 0.047481171786785126 \n",
      "Epoch: 61 | MAE Train Loss: 0.037348467856645584 | MAE Test Loss: 0.04694749787449837 \n",
      "Epoch: 62 | MAE Train Loss: 0.036891259253025055 | MAE Test Loss: 0.046413831412792206 \n",
      "Epoch: 63 | MAE Train Loss: 0.036434050649404526 | MAE Test Loss: 0.045880164951086044 \n",
      "Epoch: 64 | MAE Train Loss: 0.03598027676343918 | MAE Test Loss: 0.045027971267700195 \n",
      "Epoch: 65 | MAE Train Loss: 0.03552427887916565 | MAE Test Loss: 0.04449429363012314 \n",
      "Epoch: 66 | MAE Train Loss: 0.035067059099674225 | MAE Test Loss: 0.04396062344312668 \n",
      "Epoch: 67 | MAE Train Loss: 0.034609854221343994 | MAE Test Loss: 0.04342695325613022 \n",
      "Epoch: 68 | MAE Train Loss: 0.03415265306830406 | MAE Test Loss: 0.04289328306913376 \n",
      "Epoch: 69 | MAE Train Loss: 0.033695437014102936 | MAE Test Loss: 0.04235963150858879 \n",
      "Epoch: 70 | MAE Train Loss: 0.03323874622583389 | MAE Test Loss: 0.04150742292404175 \n",
      "Epoch: 71 | MAE Train Loss: 0.03278566151857376 | MAE Test Loss: 0.04097375646233559 \n",
      "Epoch: 72 | MAE Train Loss: 0.03232844918966293 | MAE Test Loss: 0.04044008255004883 \n",
      "Epoch: 73 | MAE Train Loss: 0.031871248036623 | MAE Test Loss: 0.03990641608834267 \n",
      "Epoch: 74 | MAE Train Loss: 0.03141402825713158 | MAE Test Loss: 0.03937274590134621 \n",
      "Epoch: 75 | MAE Train Loss: 0.030956828966736794 | MAE Test Loss: 0.038839083164930344 \n",
      "Epoch: 76 | MAE Train Loss: 0.030499618500471115 | MAE Test Loss: 0.03830542415380478 \n",
      "Epoch: 77 | MAE Train Loss: 0.030044641345739365 | MAE Test Loss: 0.037453215569257736 \n",
      "Epoch: 78 | MAE Train Loss: 0.02958984114229679 | MAE Test Loss: 0.03691954165697098 \n",
      "Epoch: 79 | MAE Train Loss: 0.02913263440132141 | MAE Test Loss: 0.03638587146997452 \n",
      "Epoch: 80 | MAE Train Loss: 0.028675425797700882 | MAE Test Loss: 0.03585221618413925 \n",
      "Epoch: 81 | MAE Train Loss: 0.02821822091937065 | MAE Test Loss: 0.0353185310959816 \n",
      "Epoch: 82 | MAE Train Loss: 0.027761003002524376 | MAE Test Loss: 0.03478487953543663 \n",
      "Epoch: 83 | MAE Train Loss: 0.02730379067361355 | MAE Test Loss: 0.03425120189785957 \n",
      "Epoch: 84 | MAE Train Loss: 0.026850532740354538 | MAE Test Loss: 0.03339900076389313 \n",
      "Epoch: 85 | MAE Train Loss: 0.02639402449131012 | MAE Test Loss: 0.032865315675735474 \n",
      "Epoch: 86 | MAE Train Loss: 0.025936812162399292 | MAE Test Loss: 0.03233165293931961 \n",
      "Epoch: 87 | MAE Train Loss: 0.025479599833488464 | MAE Test Loss: 0.031797997653484344 \n",
      "Epoch: 88 | MAE Train Loss: 0.025022396817803383 | MAE Test Loss: 0.031264323741197586 \n",
      "Epoch: 89 | MAE Train Loss: 0.024565180763602257 | MAE Test Loss: 0.030730661004781723 \n",
      "Epoch: 90 | MAE Train Loss: 0.0241090040653944 | MAE Test Loss: 0.029878471046686172 \n",
      "Epoch: 91 | MAE Train Loss: 0.02365540713071823 | MAE Test Loss: 0.02934478595852852 \n",
      "Epoch: 92 | MAE Train Loss: 0.0231982059776783 | MAE Test Loss: 0.028811108320951462 \n",
      "Epoch: 93 | MAE Train Loss: 0.022740991786122322 | MAE Test Loss: 0.028277460485696793 \n",
      "Epoch: 94 | MAE Train Loss: 0.022283781319856644 | MAE Test Loss: 0.027743777260184288 \n",
      "Epoch: 95 | MAE Train Loss: 0.021826576441526413 | MAE Test Loss: 0.027210116386413574 \n",
      "Epoch: 96 | MAE Train Loss: 0.021369364112615585 | MAE Test Loss: 0.026676446199417114 \n",
      "Epoch: 97 | MAE Train Loss: 0.020914895460009575 | MAE Test Loss: 0.02582423947751522 \n",
      "Epoch: 98 | MAE Train Loss: 0.02045958861708641 | MAE Test Loss: 0.02529056929051876 \n",
      "Epoch: 99 | MAE Train Loss: 0.02000238373875618 | MAE Test Loss: 0.0247568991035223 \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs=100\n",
    "\n",
    "train_loss_values=[]\n",
    "test_loss_values=[]\n",
    "epoch_count=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #Train\n",
    "    model_lr.train()\n",
    "\n",
    "    y_pred=model_lr(X_train)\n",
    "\n",
    "    loss=loss_fn(y_pred,y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    #Test\n",
    "    model_lr.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred=model_lr(X_test)\n",
    "\n",
    "        test_loss=loss_fn(test_pred,y_test.type(torch.float))\n",
    "        print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d28105e8-44fc-41e2-a986-ea28f7d26c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7722],\n",
       "        [0.6980],\n",
       "        [0.9328],\n",
       "        [0.3769],\n",
       "        [0.4880],\n",
       "        [0.4016],\n",
       "        [0.8463],\n",
       "        [0.8586],\n",
       "        [0.6733],\n",
       "        [0.8957]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Set the model in evaluation mode\n",
    "model_lr.eval()\n",
    "\n",
    "# 2. Setup the inference mode context manager\n",
    "with torch.inference_mode():\n",
    "  # 3. Make sure the calculations are done with the model and data on the same device\n",
    "  # in our case, we haven't setup device-agnostic code yet so our data and model are\n",
    "  # on the CPU by default.\n",
    "  # model_0.to(device)\n",
    "  # X_test = X_test.to(device)\n",
    "  y_preds = model_lr(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c164b3d-02b0-429c-bec3-dd634e778c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8929173-244d-46cb-abd4-ab673017732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\01_pytorch_workflow_model_lr.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path \n",
    "MODEL_NAME = \"01_pytorch_workflow_model_lr.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict \n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_lr.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3686ae01-4134-4237-9541-ba5e433218e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Check the saved file path\n",
    "!ls -l models/01_pytorch_workflow_model_0.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41096390-8c60-470c-8c90-4bd3ab404811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a new instance of our model (this will be instantiated with random weights)\n",
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "# Load the state_dict of our saved model (this will update the new instance of our model with trained weights)\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b6203fb-ad7f-4973-bd29-918cf6c553f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Put the loaded model into evaluation mode\n",
    "loaded_model_0.eval()\n",
    "\n",
    "# 2. Use the inference mode context manager to make predictions\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_model_0(X_test) # perform a forward pass on the test data with the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6ce5897-3b8e-43ea-831a-f510d4513d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare previous model predictions with loaded model predictions (these should be the same)\n",
    "y_preds == loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf3e142-18ca-43c4-82f5-04278c3c1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1,out_features=1)\n",
    "\n",
    "    def forward(self,x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aab19ec7-0fc9-47d0-b8b2-dbb27491e0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
       "             ('linear_layer.bias', tensor([0.8300]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1=LinearRegressionV2()\n",
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99b5cd09-5e8f-4ac8-b99e-addd14c76b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.L1Loss()\n",
    "\n",
    "optimizer=torch.optim.SGD(params=model_1.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86787ccd-f59c-42bc-9f39-1ec3d7ee64fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Train Loss:0.009661170653998852 | Test Loss:0.012256830930709839\n",
      "Epoch:1 | Train Loss:0.009615855291485786 | Test Loss:0.012171605601906776\n",
      "Epoch:2 | Train Loss:0.009570188820362091 | Test Loss:0.012118223123252392\n",
      "Epoch:3 | Train Loss:0.009524472057819366 | Test Loss:0.01206484716385603\n",
      "Epoch:4 | Train Loss:0.009478738531470299 | Test Loss:0.01201147772371769\n",
      "Epoch:5 | Train Loss:0.009433015249669552 | Test Loss:0.011958101764321327\n",
      "Epoch:6 | Train Loss:0.009387306869029999 | Test Loss:0.011904731392860413\n",
      "Epoch:7 | Train Loss:0.009341689758002758 | Test Loss:0.011819499544799328\n",
      "Epoch:8 | Train Loss:0.00929632131010294 | Test Loss:0.01176612637937069\n",
      "Epoch:9 | Train Loss:0.009250600822269917 | Test Loss:0.01171274483203888\n",
      "Epoch:10 | Train Loss:0.009204884059727192 | Test Loss:0.011659368872642517\n",
      "Epoch:11 | Train Loss:0.00915914960205555 | Test Loss:0.011605998501181602\n",
      "Epoch:12 | Train Loss:0.009113427251577377 | Test Loss:0.01155262254178524\n",
      "Epoch:13 | Train Loss:0.009067718870937824 | Test Loss:0.0114992531016469\n",
      "Epoch:14 | Train Loss:0.00902226846665144 | Test Loss:0.011414021253585815\n",
      "Epoch:15 | Train Loss:0.008976733312010765 | Test Loss:0.011360648088157177\n",
      "Epoch:16 | Train Loss:0.008931012824177742 | Test Loss:0.011307266540825367\n",
      "Epoch:17 | Train Loss:0.008885296061635017 | Test Loss:0.011253890581429005\n",
      "Epoch:18 | Train Loss:0.008839561603963375 | Test Loss:0.01120052020996809\n",
      "Epoch:19 | Train Loss:0.008793839253485203 | Test Loss:0.011147144250571728\n",
      "Epoch:20 | Train Loss:0.00874813087284565 | Test Loss:0.011093774810433388\n",
      "Epoch:21 | Train Loss:0.008702847175300121 | Test Loss:0.011008542962372303\n",
      "Epoch:22 | Train Loss:0.008657144382596016 | Test Loss:0.010955169796943665\n",
      "Epoch:23 | Train Loss:0.008611423894762993 | Test Loss:0.010901788249611855\n",
      "Epoch:24 | Train Loss:0.008565707132220268 | Test Loss:0.010848412290215492\n",
      "Epoch:25 | Train Loss:0.0085199736058712 | Test Loss:0.010795041918754578\n",
      "Epoch:26 | Train Loss:0.008474251255393028 | Test Loss:0.010741665959358215\n",
      "Epoch:27 | Train Loss:0.008428685367107391 | Test Loss:0.010656451806426048\n",
      "Epoch:28 | Train Loss:0.00838327594101429 | Test Loss:0.01060306467115879\n",
      "Epoch:29 | Train Loss:0.008337556384503841 | Test Loss:0.010549691505730152\n",
      "Epoch:30 | Train Loss:0.008291835896670818 | Test Loss:0.010496309027075768\n",
      "Epoch:31 | Train Loss:0.008246119134128094 | Test Loss:0.010442933067679405\n",
      "Epoch:32 | Train Loss:0.008200385607779026 | Test Loss:0.010389563627541065\n",
      "Epoch:33 | Train Loss:0.008154662325978279 | Test Loss:0.010336187668144703\n",
      "Epoch:34 | Train Loss:0.008109264075756073 | Test Loss:0.010250973515212536\n",
      "Epoch:35 | Train Loss:0.00806368701159954 | Test Loss:0.010197585448622704\n",
      "Epoch:36 | Train Loss:0.008017968386411667 | Test Loss:0.01014421321451664\n",
      "Epoch:37 | Train Loss:0.007972247898578644 | Test Loss:0.010090830735862255\n",
      "Epoch:38 | Train Loss:0.00792653113603592 | Test Loss:0.010037454776465893\n",
      "Epoch:39 | Train Loss:0.007880797609686852 | Test Loss:0.009984085336327553\n",
      "Epoch:40 | Train Loss:0.007835089229047298 | Test Loss:0.009898850694298744\n",
      "Epoch:41 | Train Loss:0.0077898227609694 | Test Loss:0.009845483116805553\n",
      "Epoch:42 | Train Loss:0.007744099013507366 | Test Loss:0.009792107157409191\n",
      "Epoch:43 | Train Loss:0.007698380388319492 | Test Loss:0.009738733991980553\n",
      "Epoch:44 | Train Loss:0.007652659900486469 | Test Loss:0.009685352444648743\n",
      "Epoch:45 | Train Loss:0.007606943137943745 | Test Loss:0.00963197648525238\n",
      "Epoch:46 | Train Loss:0.00756120914593339 | Test Loss:0.009578606113791466\n",
      "Epoch:47 | Train Loss:0.00751566793769598 | Test Loss:0.009493371471762657\n",
      "Epoch:48 | Train Loss:0.007470234297215939 | Test Loss:0.009440004825592041\n",
      "Epoch:49 | Train Loss:0.007424511015415192 | Test Loss:0.009386628866195679\n",
      "Epoch:50 | Train Loss:0.0073787919245660305 | Test Loss:0.00933325570076704\n",
      "Epoch:51 | Train Loss:0.007333071436733007 | Test Loss:0.00927987415343523\n",
      "Epoch:52 | Train Loss:0.007287354674190283 | Test Loss:0.009226498194038868\n",
      "Epoch:53 | Train Loss:0.007241620682179928 | Test Loss:0.009173127822577953\n",
      "Epoch:54 | Train Loss:0.007196246646344662 | Test Loss:0.009087893180549145\n",
      "Epoch:55 | Train Loss:0.007150646299123764 | Test Loss:0.009034526534378529\n",
      "Epoch:56 | Train Loss:0.007104923017323017 | Test Loss:0.008981150574982166\n",
      "Epoch:57 | Train Loss:0.007059203926473856 | Test Loss:0.008927777409553528\n",
      "Epoch:58 | Train Loss:0.007013483438640833 | Test Loss:0.008874395862221718\n",
      "Epoch:59 | Train Loss:0.006967766676098108 | Test Loss:0.008821019902825356\n",
      "Epoch:60 | Train Loss:0.006922086235135794 | Test Loss:0.008735781535506248\n",
      "Epoch:61 | Train Loss:0.006876775063574314 | Test Loss:0.008682414889335632\n",
      "Epoch:62 | Train Loss:0.0068310583010315895 | Test Loss:0.008629048243165016\n",
      "Epoch:63 | Train Loss:0.006785334553569555 | Test Loss:0.008575672283768654\n",
      "Epoch:64 | Train Loss:0.006739615462720394 | Test Loss:0.008522299118340015\n",
      "Epoch:65 | Train Loss:0.006693894974887371 | Test Loss:0.00846891663968563\n",
      "Epoch:66 | Train Loss:0.0066481782123446465 | Test Loss:0.008415540680289268\n",
      "Epoch:67 | Train Loss:0.006602664943784475 | Test Loss:0.008330303244292736\n",
      "Epoch:68 | Train Loss:0.006557186599820852 | Test Loss:0.00827693659812212\n",
      "Epoch:69 | Train Loss:0.006511469837278128 | Test Loss:0.00822356902062893\n",
      "Epoch:70 | Train Loss:0.006465746555477381 | Test Loss:0.008170193061232567\n",
      "Epoch:71 | Train Loss:0.00642002746462822 | Test Loss:0.008116820827126503\n",
      "Epoch:72 | Train Loss:0.0063743069767951965 | Test Loss:0.008063438348472118\n",
      "Epoch:73 | Train Loss:0.006328590214252472 | Test Loss:0.008010062389075756\n",
      "Epoch:74 | Train Loss:0.006283243652433157 | Test Loss:0.007924824953079224\n",
      "Epoch:75 | Train Loss:0.006237598601728678 | Test Loss:0.007871458306908607\n",
      "Epoch:76 | Train Loss:0.006191881839185953 | Test Loss:0.007818090729415417\n",
      "Epoch:77 | Train Loss:0.006146158091723919 | Test Loss:0.007764714770019054\n",
      "Epoch:78 | Train Loss:0.006100439466536045 | Test Loss:0.007711342070251703\n",
      "Epoch:79 | Train Loss:0.006054718978703022 | Test Loss:0.007657960057258606\n",
      "Epoch:80 | Train Loss:0.0060090916231274605 | Test Loss:0.007572728209197521\n",
      "Epoch:81 | Train Loss:0.0059637343510985374 | Test Loss:0.007519346661865711\n",
      "Epoch:82 | Train Loss:0.005918010137975216 | Test Loss:0.007465979550033808\n",
      "Epoch:83 | Train Loss:0.005872293375432491 | Test Loss:0.007412612438201904\n",
      "Epoch:84 | Train Loss:0.005826570093631744 | Test Loss:0.007359236478805542\n",
      "Epoch:85 | Train Loss:0.005780851002782583 | Test Loss:0.0073058633133769035\n",
      "Epoch:86 | Train Loss:0.005735131911933422 | Test Loss:0.0072524817660450935\n",
      "Epoch:87 | Train Loss:0.005689670331776142 | Test Loss:0.007167249917984009\n",
      "Epoch:88 | Train Loss:0.005644146353006363 | Test Loss:0.0071138679049909115\n",
      "Epoch:89 | Train Loss:0.005598423536866903 | Test Loss:0.007060500793159008\n",
      "Epoch:90 | Train Loss:0.005552705377340317 | Test Loss:0.007007134146988392\n",
      "Epoch:91 | Train Loss:0.005506983492523432 | Test Loss:0.00695375818759203\n",
      "Epoch:92 | Train Loss:0.005461263004690409 | Test Loss:0.006900385022163391\n",
      "Epoch:93 | Train Loss:0.0054155439138412476 | Test Loss:0.006847003009170294\n",
      "Epoch:94 | Train Loss:0.005370249040424824 | Test Loss:0.006761771626770496\n",
      "Epoch:95 | Train Loss:0.005324558354914188 | Test Loss:0.006708389613777399\n",
      "Epoch:96 | Train Loss:0.005278835538774729 | Test Loss:0.006655022501945496\n",
      "Epoch:97 | Train Loss:0.005233117379248142 | Test Loss:0.006601655390113592\n",
      "Epoch:98 | Train Loss:0.00518739502876997 | Test Loss:0.00654827943071723\n",
      "Epoch:99 | Train Loss:0.005141674540936947 | Test Loss:0.006494906730949879\n",
      "Epoch:100 | Train Loss:0.005096083972603083 | Test Loss:0.006409666035324335\n",
      "Epoch:101 | Train Loss:0.005050695035606623 | Test Loss:0.006356292869895697\n",
      "Epoch:102 | Train Loss:0.0050049698911607265 | Test Loss:0.006302910856902599\n",
      "Epoch:103 | Train Loss:0.004959247075021267 | Test Loss:0.006249544210731983\n",
      "Epoch:104 | Train Loss:0.00491352891549468 | Test Loss:0.00619617709890008\n",
      "Epoch:105 | Train Loss:0.004867807030677795 | Test Loss:0.006142801139503717\n",
      "Epoch:106 | Train Loss:0.004822086542844772 | Test Loss:0.006089427974075079\n",
      "Epoch:107 | Train Loss:0.004776662681251764 | Test Loss:0.006004187278449535\n",
      "Epoch:108 | Train Loss:0.004731106571853161 | Test Loss:0.005950814578682184\n",
      "Epoch:109 | Train Loss:0.004685381893068552 | Test Loss:0.005897432565689087\n",
      "Epoch:110 | Train Loss:0.004639658145606518 | Test Loss:0.0058440654538571835\n",
      "Epoch:111 | Train Loss:0.004593940917402506 | Test Loss:0.00579069834202528\n",
      "Epoch:112 | Train Loss:0.004548219032585621 | Test Loss:0.005737322382628918\n",
      "Epoch:113 | Train Loss:0.004502499010413885 | Test Loss:0.005668035242706537\n",
      "Epoch:114 | Train Loss:0.004457014612853527 | Test Loss:0.00561466533690691\n",
      "Epoch:115 | Train Loss:0.004411292262375355 | Test Loss:0.0055612861178815365\n",
      "Epoch:116 | Train Loss:0.0043655699118971825 | Test Loss:0.005507910158485174\n",
      "Epoch:117 | Train Loss:0.004320166073739529 | Test Loss:0.005422681570053101\n",
      "Epoch:118 | Train Loss:0.004274580627679825 | Test Loss:0.005369314458221197\n",
      "Epoch:119 | Train Loss:0.004228864796459675 | Test Loss:0.005315935704857111\n",
      "Epoch:120 | Train Loss:0.0041831424459815025 | Test Loss:0.0052625564858317375\n",
      "Epoch:121 | Train Loss:0.0041374266147613525 | Test Loss:0.00520918658003211\n",
      "Epoch:122 | Train Loss:0.004091703798621893 | Test Loss:0.005155807826668024\n",
      "Epoch:123 | Train Loss:0.004045999608933926 | Test Loss:0.005070582032203674\n",
      "Epoch:124 | Train Loss:0.004000718239694834 | Test Loss:0.005017203278839588\n",
      "Epoch:125 | Train Loss:0.00395499262958765 | Test Loss:0.004963836167007685\n",
      "Epoch:126 | Train Loss:0.003909276332706213 | Test Loss:0.004910456947982311\n",
      "Epoch:127 | Train Loss:0.003863554447889328 | Test Loss:0.004857078194618225\n",
      "Epoch:128 | Train Loss:0.0038178383838385344 | Test Loss:0.004803708288818598\n",
      "Epoch:129 | Train Loss:0.0037721158005297184 | Test Loss:0.004750329069793224\n",
      "Epoch:130 | Train Loss:0.003726578550413251 | Test Loss:0.004665103740990162\n",
      "Epoch:131 | Train Loss:0.0036811300087720156 | Test Loss:0.0046117245219647884\n",
      "Epoch:132 | Train Loss:0.0036354041658341885 | Test Loss:0.004558357410132885\n",
      "Epoch:133 | Train Loss:0.0035896883346140385 | Test Loss:0.004504978656768799\n",
      "Epoch:134 | Train Loss:0.00354396621696651 | Test Loss:0.004451599903404713\n",
      "Epoch:135 | Train Loss:0.003498250152915716 | Test Loss:0.004398229531943798\n",
      "Epoch:136 | Train Loss:0.0034525275696069 | Test Loss:0.004344850778579712\n",
      "Epoch:137 | Train Loss:0.0034071572590619326 | Test Loss:0.004259624984115362\n",
      "Epoch:138 | Train Loss:0.0033615417778491974 | Test Loss:0.004206246230751276\n",
      "Epoch:139 | Train Loss:0.003315816167742014 | Test Loss:0.0041528791189193726\n",
      "Epoch:140 | Train Loss:0.0032701001036912203 | Test Loss:0.004099500365555286\n",
      "Epoch:141 | Train Loss:0.0032243779860436916 | Test Loss:0.004046121146529913\n",
      "Epoch:142 | Train Loss:0.0031786621548235416 | Test Loss:0.003992751240730286\n",
      "Epoch:143 | Train Loss:0.00313299591653049 | Test Loss:0.003907513804733753\n",
      "Epoch:144 | Train Loss:0.003087675664573908 | Test Loss:0.0038541466929018497\n",
      "Epoch:145 | Train Loss:0.003041953546926379 | Test Loss:0.00380076770670712\n",
      "Epoch:146 | Train Loss:0.0029962279368191957 | Test Loss:0.0037474005948752165\n",
      "Epoch:147 | Train Loss:0.002950511872768402 | Test Loss:0.0036940216086804867\n",
      "Epoch:148 | Train Loss:0.002904789987951517 | Test Loss:0.0036406428553164005\n",
      "Epoch:149 | Train Loss:0.0028590739239007235 | Test Loss:0.0035872727166861296\n",
      "Epoch:150 | Train Loss:0.0028135746251791716 | Test Loss:0.0035020350478589535\n",
      "Epoch:151 | Train Loss:0.0027680874336510897 | Test Loss:0.0034486681688576937\n",
      "Epoch:152 | Train Loss:0.002722365316003561 | Test Loss:0.003395289182662964\n",
      "Epoch:153 | Train Loss:0.0026766397058963776 | Test Loss:0.0033419220708310604\n",
      "Epoch:154 | Train Loss:0.002630923641845584 | Test Loss:0.0032885433174669743\n",
      "Epoch:155 | Train Loss:0.002585201757028699 | Test Loss:0.0032351643312722445\n",
      "Epoch:156 | Train Loss:0.0025394856929779053 | Test Loss:0.0031817941926419735\n",
      "Epoch:157 | Train Loss:0.002494153333827853 | Test Loss:0.003096556756645441\n",
      "Epoch:158 | Train Loss:0.0024484992027282715 | Test Loss:0.0030431896448135376\n",
      "Epoch:159 | Train Loss:0.0024027773179113865 | Test Loss:0.002989810658618808\n",
      "Epoch:160 | Train Loss:0.0023570514749735594 | Test Loss:0.002936443779617548\n",
      "Epoch:161 | Train Loss:0.0023113354109227657 | Test Loss:0.002883064793422818\n",
      "Epoch:162 | Train Loss:0.0022656135261058807 | Test Loss:0.0028296858072280884\n",
      "Epoch:163 | Train Loss:0.002219992922618985 | Test Loss:0.002744445111602545\n",
      "Epoch:164 | Train Loss:0.002174635883420706 | Test Loss:0.002691078232601285\n",
      "Epoch:165 | Train Loss:0.0021289109718054533 | Test Loss:0.0026377111207693815\n",
      "Epoch:166 | Train Loss:0.0020831890869885683 | Test Loss:0.0025843321345746517\n",
      "Epoch:167 | Train Loss:0.002037463244050741 | Test Loss:0.002530965255573392\n",
      "Epoch:168 | Train Loss:0.001991747412830591 | Test Loss:0.002477586269378662\n",
      "Epoch:169 | Train Loss:0.0019460252951830626 | Test Loss:0.0024242072831839323\n",
      "Epoch:170 | Train Loss:0.0019005716312676668 | Test Loss:0.0023389668203890324\n",
      "Epoch:171 | Train Loss:0.0018550477689132094 | Test Loss:0.002285599708557129\n",
      "Epoch:172 | Train Loss:0.001809322857297957 | Test Loss:0.0022322325967252254\n",
      "Epoch:173 | Train Loss:0.0017636008560657501 | Test Loss:0.0021788538433611393\n",
      "Epoch:174 | Train Loss:0.0017178751295432448 | Test Loss:0.002125486731529236\n",
      "Epoch:175 | Train Loss:0.001672159181907773 | Test Loss:0.002072107745334506\n",
      "Epoch:176 | Train Loss:0.0016264371806755662 | Test Loss:0.0020187287591397762\n",
      "Epoch:177 | Train Loss:0.0015811503399163485 | Test Loss:0.0019334882963448763\n",
      "Epoch:178 | Train Loss:0.001535459654405713 | Test Loss:0.0018801211845129728\n",
      "Epoch:179 | Train Loss:0.0014897346263751388 | Test Loss:0.0018267541890963912\n",
      "Epoch:180 | Train Loss:0.001444012625142932 | Test Loss:0.0017733753193169832\n",
      "Epoch:181 | Train Loss:0.0013982870150357485 | Test Loss:0.0017200082074850798\n",
      "Epoch:182 | Train Loss:0.0013525709509849548 | Test Loss:0.0016666293377056718\n",
      "Epoch:183 | Train Loss:0.001306980149820447 | Test Loss:0.00158138875849545\n",
      "Epoch:184 | Train Loss:0.0012615814339369535 | Test Loss:0.0015280097723007202\n",
      "Epoch:185 | Train Loss:0.001215871423482895 | Test Loss:0.0014746427768841386\n",
      "Epoch:186 | Train Loss:0.0011701465118676424 | Test Loss:0.001421275781467557\n",
      "Epoch:187 | Train Loss:0.0011244245106354356 | Test Loss:0.0013678967952728271\n",
      "Epoch:188 | Train Loss:0.001078700297512114 | Test Loss:0.0013145297998562455\n",
      "Epoch:189 | Train Loss:0.0010329827200621367 | Test Loss:0.0012611508136615157\n",
      "Epoch:190 | Train Loss:0.0009875588584691286 | Test Loss:0.001175910234451294\n",
      "Epoch:191 | Train Loss:0.0009419933194294572 | Test Loss:0.0011225312482565641\n",
      "Epoch:192 | Train Loss:0.0008962832507677376 | Test Loss:0.0010691642528399825\n",
      "Epoch:193 | Train Loss:0.0008505582809448242 | Test Loss:0.0010157972574234009\n",
      "Epoch:194 | Train Loss:0.0008048362797126174 | Test Loss:0.000962418329436332\n",
      "Epoch:195 | Train Loss:0.0007591135799884796 | Test Loss:0.0009090512758120894\n",
      "Epoch:196 | Train Loss:0.0007133946055546403 | Test Loss:0.0008397608762606978\n",
      "Epoch:197 | Train Loss:0.0006679080543108284 | Test Loss:0.000786387943662703\n",
      "Epoch:198 | Train Loss:0.0006221838411875069 | Test Loss:0.0007330208900384605\n",
      "Epoch:199 | Train Loss:0.0005764610832557082 | Test Loss:0.000679638993460685\n",
      "Epoch:200 | Train Loss:0.0005310646956786513 | Test Loss:0.000594407320022583\n",
      "Epoch:201 | Train Loss:0.0004857510211877525 | Test Loss:0.0005733996513299644\n",
      "Epoch:202 | Train Loss:0.00044076592894271016 | Test Loss:0.0004881650093011558\n",
      "Epoch:203 | Train Loss:0.0003942310868296772 | Test Loss:0.0004347860813140869\n",
      "Epoch:204 | Train Loss:0.0003485001507215202 | Test Loss:0.00038141608820296824\n",
      "Epoch:205 | Train Loss:0.0003027863858733326 | Test Loss:0.0003280550299677998\n",
      "Epoch:206 | Train Loss:0.0002571135701145977 | Test Loss:0.00024281740479636937\n",
      "Epoch:207 | Train Loss:0.00021431893401313573 | Test Loss:0.0002546489122323692\n",
      "Epoch:208 | Train Loss:0.00017944350838661194 | Test Loss:0.00023108124150894582\n",
      "Epoch:209 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:210 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:211 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:212 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:213 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:214 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:215 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:216 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:217 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:218 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:219 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:220 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:221 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:222 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:223 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:224 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:225 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:226 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:227 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:228 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:229 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:230 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:231 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:232 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:233 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:234 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:235 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:236 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:237 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:238 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:239 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:240 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:241 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:242 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:243 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:244 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:245 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:246 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:247 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:248 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:249 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:250 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:251 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:252 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:253 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:254 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:255 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:256 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:257 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:258 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:259 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:260 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:261 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:262 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:263 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:264 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:265 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:266 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:267 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:268 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:269 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:270 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:271 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:272 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:273 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:274 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:275 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:276 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:277 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:278 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:279 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:280 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:281 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:282 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:283 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:284 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:285 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:286 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:287 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:288 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:289 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:290 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:291 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:292 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:293 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:294 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:295 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:296 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:297 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:298 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:299 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:300 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:301 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:302 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:303 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:304 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:305 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:306 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:307 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:308 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:309 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:310 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:311 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:312 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:313 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:314 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:315 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:316 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:317 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:318 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:319 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:320 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:321 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:322 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:323 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:324 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:325 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:326 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:327 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:328 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:329 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:330 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:331 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:332 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:333 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:334 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:335 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:336 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:337 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:338 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:339 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:340 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:341 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:342 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:343 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:344 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:345 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:346 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:347 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:348 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:349 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:350 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:351 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:352 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:353 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:354 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:355 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:356 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:357 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:358 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:359 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:360 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:361 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:362 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:363 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:364 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:365 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:366 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:367 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:368 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:369 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:370 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:371 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:372 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:373 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:374 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:375 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:376 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:377 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:378 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:379 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:380 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:381 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:382 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:383 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:384 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:385 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:386 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:387 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:388 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:389 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:390 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:391 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:392 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:393 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:394 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:395 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:396 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:397 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:398 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:399 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:400 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:401 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:402 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:403 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:404 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:405 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:406 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:407 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:408 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:409 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:410 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:411 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:412 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:413 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:414 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:415 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:416 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:417 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:418 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:419 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:420 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:421 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:422 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:423 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:424 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:425 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:426 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:427 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:428 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:429 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:430 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:431 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:432 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:433 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:434 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:435 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:436 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:437 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:438 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:439 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:440 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:441 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:442 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:443 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:444 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:445 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:446 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:447 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:448 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:449 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:450 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:451 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:452 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:453 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:454 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:455 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:456 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:457 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:458 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:459 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:460 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:461 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:462 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:463 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:464 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:465 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:466 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:467 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:468 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:469 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:470 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:471 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:472 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:473 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:474 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:475 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:476 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:477 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:478 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:479 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:480 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:481 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:482 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:483 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:484 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:485 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:486 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:487 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:488 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:489 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:490 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:491 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:492 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:493 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:494 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:495 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:496 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:497 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:498 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:499 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:500 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:501 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:502 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:503 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:504 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:505 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:506 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:507 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:508 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:509 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:510 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:511 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:512 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:513 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:514 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:515 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:516 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:517 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:518 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:519 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:520 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:521 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:522 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:523 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:524 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:525 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:526 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:527 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:528 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:529 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:530 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:531 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:532 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:533 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:534 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:535 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:536 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:537 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:538 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:539 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:540 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:541 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:542 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:543 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:544 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:545 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:546 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:547 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:548 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:549 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:550 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:551 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:552 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:553 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:554 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:555 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:556 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:557 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:558 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:559 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:560 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:561 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:562 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:563 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:564 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:565 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:566 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:567 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:568 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:569 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:570 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:571 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:572 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:573 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:574 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:575 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:576 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:577 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:578 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:579 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:580 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:581 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:582 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:583 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:584 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:585 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:586 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:587 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:588 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:589 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:590 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:591 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:592 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:593 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:594 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:595 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:596 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:597 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:598 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:599 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:600 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:601 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:602 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:603 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:604 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:605 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:606 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:607 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:608 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:609 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:610 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:611 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:612 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:613 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:614 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:615 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:616 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:617 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:618 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:619 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:620 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:621 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:622 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:623 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:624 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:625 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:626 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:627 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:628 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:629 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:630 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:631 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:632 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:633 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:634 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:635 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:636 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:637 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:638 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:639 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:640 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:641 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:642 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:643 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:644 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:645 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:646 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:647 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:648 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:649 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:650 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:651 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:652 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:653 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:654 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:655 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:656 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:657 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:658 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:659 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:660 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:661 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:662 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:663 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:664 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:665 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:666 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:667 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:668 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:669 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:670 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:671 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:672 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:673 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:674 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:675 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:676 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:677 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:678 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:679 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:680 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:681 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:682 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:683 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:684 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:685 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:686 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:687 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:688 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:689 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:690 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:691 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:692 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:693 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:694 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:695 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:696 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:697 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:698 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:699 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:700 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:701 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:702 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:703 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:704 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:705 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:706 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:707 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:708 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:709 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:710 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:711 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:712 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:713 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:714 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:715 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:716 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:717 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:718 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:719 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:720 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:721 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:722 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:723 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:724 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:725 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:726 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:727 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:728 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:729 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:730 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:731 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:732 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:733 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:734 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:735 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:736 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:737 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:738 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:739 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:740 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:741 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:742 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:743 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:744 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:745 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:746 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:747 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:748 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:749 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:750 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:751 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:752 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:753 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:754 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:755 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:756 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:757 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:758 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:759 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:760 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:761 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:762 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:763 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:764 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:765 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:766 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:767 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:768 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:769 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:770 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:771 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:772 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:773 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:774 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:775 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:776 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:777 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:778 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:779 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:780 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:781 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:782 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:783 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:784 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:785 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:786 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:787 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:788 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:789 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:790 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:791 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:792 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:793 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:794 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:795 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:796 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:797 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:798 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:799 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:800 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:801 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:802 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:803 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:804 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:805 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:806 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:807 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:808 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:809 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:810 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:811 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:812 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:813 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:814 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:815 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:816 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:817 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:818 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:819 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:820 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:821 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:822 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:823 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:824 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:825 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:826 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:827 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:828 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:829 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:830 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:831 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:832 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:833 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:834 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:835 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:836 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:837 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:838 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:839 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:840 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:841 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:842 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:843 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:844 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:845 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:846 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:847 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:848 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:849 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:850 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:851 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:852 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:853 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:854 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:855 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:856 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:857 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:858 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:859 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:860 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:861 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:862 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:863 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:864 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:865 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:866 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:867 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:868 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:869 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:870 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:871 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:872 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:873 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:874 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:875 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:876 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:877 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:878 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:879 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:880 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:881 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:882 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:883 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:884 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:885 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:886 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:887 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:888 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:889 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:890 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:891 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:892 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:893 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:894 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:895 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:896 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:897 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:898 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:899 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:900 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:901 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:902 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:903 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:904 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:905 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:906 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:907 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:908 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:909 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:910 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:911 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:912 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:913 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:914 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:915 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:916 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:917 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:918 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:919 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:920 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:921 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:922 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:923 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:924 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:925 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:926 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:927 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:928 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:929 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:930 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:931 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:932 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:933 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:934 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:935 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:936 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:937 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:938 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:939 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:940 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:941 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:942 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:943 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:944 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:945 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:946 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:947 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:948 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:949 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:950 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:951 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:952 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:953 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:954 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:955 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:956 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:957 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:958 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:959 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:960 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:961 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:962 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:963 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:964 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:965 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:966 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:967 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:968 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:969 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:970 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:971 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:972 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:973 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:974 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:975 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:976 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:977 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:978 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:979 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:980 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:981 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:982 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:983 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:984 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:985 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:986 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:987 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:988 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:989 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:990 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:991 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:992 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:993 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:994 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:995 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:996 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:997 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n",
      "Epoch:998 | Train Loss:0.0009451910736970603 | Test Loss:0.00023108124150894582\n",
      "Epoch:999 | Train Loss:0.0002747759281191975 | Test Loss:0.0010381012689322233\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs=1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #Train\n",
    "    model_1.train()\n",
    "    y_pred=model_1(X_train)\n",
    "    loss=loss_fn(y_pred,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #Test\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred=model_1(X_test)\n",
    "        test_loss=loss_fn(test_pred,y_test)\n",
    "    if epochs % 100 == 0:\n",
    "        print(f\"Epoch:{epoch} | Train Loss:{loss} | Test Loss:{test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6749d90f-ead9-47be-adfb-ddf3975a566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('linear_layer.weight', tensor([[0.6991]])),\n",
      "             ('linear_layer.bias', tensor([0.2995]))])\n",
      "\n",
      "And the original values for weights and bias are:\n",
      "weights: 0.7, bias: 0.3\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint # pprint = pretty print, see: https://docs.python.org/3/library/pprint.html \n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "pprint(model_1.state_dict())\n",
    "print(\"\\nAnd the original values for weights and bias are:\")\n",
    "print(f\"weights: {weight}, bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91175f88-9faa-4052-a5d2-91a2a0cf221e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7889],\n",
       "        [0.7050],\n",
       "        [0.9706],\n",
       "        [0.3414],\n",
       "        [0.4673],\n",
       "        [0.3694],\n",
       "        [0.8727],\n",
       "        [0.8867],\n",
       "        [0.6770],\n",
       "        [0.9287]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.eval()\n",
    "\n",
    "# Make predictions on the test data\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_1(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccaae007-554b-4399-84fd-80a35d203745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=y_preds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e1d6925-4b1d-4228-ac34-7bf23a846f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\01_pytorch_workflow_model_1.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path \n",
    "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict \n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model_1.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95686a3c-e4d5-4b6e-ba0d-1bba2436fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model:\n",
      "LinearRegressionV2(\n",
      "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loaded_model_1 = LinearRegressionV2()\n",
    "\n",
    "# Load model state dict \n",
    "loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "print(f\"Loaded model:\\n{loaded_model_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "774e5237-35e6-40da-a967-4d59781f4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_1_preds = loaded_model_1(X_test)\n",
    "y_preds == loaded_model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b4a2a-a4dc-4882-933d-ce97a47deea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
